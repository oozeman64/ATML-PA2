{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wW9j4GVuB-Lw"
      },
      "source": [
        "## IRMv1 with ResNet18 (Adam)\n",
        "\n",
        "#### Source Domains: PACS Art/Painting, Cartoon, Photo\n",
        "#### Target Domain: PACS Sketch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UQc2GiCVB-Ly"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, ConcatDataset, random_split\n",
        "from domainbed.algorithms import IRM\n",
        "from domainbed import algorithms, networks\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VGmTDHeEB-Lz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fixed random seed: 42\n"
          ]
        }
      ],
      "source": [
        "def fix_random_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    print(f\"Fixed random seed: {seed}\")\n",
        "\n",
        "fix_random_seed(42)\n",
        "\n",
        "# For deterministic DataLoader behavior\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CjbVGvcFB-Lz"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Program Files\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Program Files\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "hparams = {\n",
        "    'lr': 0.001,\n",
        "    'weight_decay': 0,\n",
        "    'irm_lambda': 50,\n",
        "    'irm_penalty_anneal_iters': 75,\n",
        "\n",
        "    'nonlinear_classifier': 0,\n",
        "    'resnet18': 1,\n",
        "    'resnet_dropout': 0.0,\n",
        "    'freeze_bn': 0,\n",
        "\n",
        "    'mlp_width': 1024,\n",
        "    'mlp_depth': 3,\n",
        "    'mlp_dropout': 0.1,\n",
        "    'vit': 0,\n",
        "    'dinov2': 0,\n",
        "    'vit_dropout': 0.0,\n",
        "    'vit_attn_tune': 0,\n",
        "}\n",
        "\n",
        "\n",
        "# --- Initialize IRM ---\n",
        "irm = algorithms.IRM(\n",
        "    input_shape=(3, 224, 224),\n",
        "    num_classes=7,\n",
        "    num_domains=3,\n",
        "    hparams=hparams\n",
        ").to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IYQOLbqTB-L0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Samples per domain:\n",
            "  Art total: 2048 | Train: 1945 | Val: 103\n",
            "  Cartoon total: 2344 | Train: 2226 | Val: 118\n",
            "  Photo total: 1670 | Train: 1586 | Val: 84\n",
            "  Sketch total (target): 3929\n",
            "\n",
            "Combined Train Samples: 5757\n",
            "Combined Val Samples:   305\n"
          ]
        }
      ],
      "source": [
        "# --- Constants ---\n",
        "imagenet_mean = [0.485, 0.456, 0.406]\n",
        "imagenet_std = [0.229, 0.224, 0.225]\n",
        "BATCH_SIZE = 64\n",
        "NUM_WORKERS = 0\n",
        "TRAIN_RATIO = 0.95\n",
        "VAL_RATIO = 0.05\n",
        "\n",
        "# --- Transform ---\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
        "])\n",
        "\n",
        "# --- Directories ---\n",
        "art_dir = \"data/pacs_data/pacs_data/art_painting\"\n",
        "cartoon_dir = \"data/pacs_data/pacs_data/cartoon\"\n",
        "photo_dir = \"data/pacs_data/pacs_data/photo\"\n",
        "sketch_dir = \"data/pacs_data/pacs_data/sketch\"\n",
        "\n",
        "# --- Datasets ---\n",
        "art_dataset = datasets.ImageFolder(root=art_dir, transform=transform)\n",
        "cartoon_dataset = datasets.ImageFolder(root=cartoon_dir, transform=transform)\n",
        "photo_dataset = datasets.ImageFolder(root=photo_dir, transform=transform)\n",
        "sketch_dataset = datasets.ImageFolder(root=sketch_dir, transform=transform)  # target domain\n",
        "\n",
        "# --- Seed setup for reproducibility ---\n",
        "g = torch.Generator()\n",
        "g.manual_seed(42)\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    torch.manual_seed(worker_seed)\n",
        "    torch.cuda.manual_seed_all(worker_seed)\n",
        "\n",
        "# --- Split each train domain into train/val ---\n",
        "def split_dataset(dataset, ratio=TRAIN_RATIO, generator=g):\n",
        "    total_size = len(dataset)\n",
        "    train_size = int(ratio * total_size)\n",
        "    val_size = total_size - train_size\n",
        "    return random_split(dataset, [train_size, val_size], generator=generator)\n",
        "\n",
        "art_train, art_val = split_dataset(art_dataset)\n",
        "cartoon_train, cartoon_val = split_dataset(cartoon_dataset)\n",
        "photo_train, photo_val = split_dataset(photo_dataset)\n",
        "\n",
        "# --- Loaders for each train domain ---\n",
        "art_train_loader = DataLoader(\n",
        "    art_train,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True,\n",
        "    worker_init_fn=seed_worker,\n",
        "    generator=g\n",
        ")\n",
        "\n",
        "cartoon_train_loader = DataLoader(\n",
        "    cartoon_train,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True,\n",
        "    worker_init_fn=seed_worker,\n",
        "    generator=g\n",
        ")\n",
        "\n",
        "photo_train_loader = DataLoader(\n",
        "    photo_train,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True,\n",
        "    worker_init_fn=seed_worker,\n",
        "    generator=g\n",
        ")\n",
        "\n",
        "\n",
        "# --- Loaders for each val domain ---\n",
        "art_val_loader = DataLoader(\n",
        "    art_val,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True,\n",
        "    worker_init_fn=seed_worker,\n",
        "    generator=g\n",
        ")\n",
        "\n",
        "cartoon_val_loader = DataLoader(\n",
        "    cartoon_val,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True,\n",
        "    worker_init_fn=seed_worker,\n",
        "    generator=g\n",
        ")\n",
        "\n",
        "photo_val_loader = DataLoader(\n",
        "    photo_val,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True,\n",
        "    worker_init_fn=seed_worker,\n",
        "    generator=g\n",
        ")\n",
        "\n",
        "# --- Combined train and val datasets for all source domains ---\n",
        "combined_train_dataset = ConcatDataset([art_train, cartoon_train, photo_train])\n",
        "combined_val_dataset = ConcatDataset([art_val, cartoon_val, photo_val])\n",
        "\n",
        "combined_train_loader = DataLoader(\n",
        "    combined_train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True,\n",
        "    worker_init_fn=seed_worker,\n",
        "    generator=g\n",
        ")\n",
        "\n",
        "combined_val_loader = DataLoader(\n",
        "    combined_val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True,\n",
        "    worker_init_fn=seed_worker,\n",
        "    generator=g\n",
        ")\n",
        "\n",
        "# --- Sketch loader (target domain) ---\n",
        "sketch_loader = DataLoader(\n",
        "    sketch_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True,\n",
        "    worker_init_fn=seed_worker,\n",
        "    generator=g\n",
        ")\n",
        "\n",
        "envs = [art_train_loader, cartoon_train_loader, photo_train_loader]\n",
        "\n",
        "# --- Debug info ---\n",
        "print(\"Samples per domain:\")\n",
        "print(f\"  Art total: {len(art_dataset)} | Train: {len(art_train)} | Val: {len(art_val)}\")\n",
        "print(f\"  Cartoon total: {len(cartoon_dataset)} | Train: {len(cartoon_train)} | Val: {len(cartoon_val)}\")\n",
        "print(f\"  Photo total: {len(photo_dataset)} | Train: {len(photo_train)} | Val: {len(photo_val)}\")\n",
        "print(f\"  Sketch total (target): {len(sketch_dataset)}\")\n",
        "print()\n",
        "print(f\"Combined Train Samples: {len(combined_train_dataset)}\")\n",
        "print(f\"Combined Val Samples:   {len(combined_val_dataset)}\")\n",
        "\n",
        "# --- Classes ---\n",
        "pacs_classes = sketch_dataset.classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fbhFeIEdB-L0"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    correct = total = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            preds = model.predict(x)\n",
        "            correct += (torch.argmax(preds, dim=1) == y).sum().item()\n",
        "            total += y.size(0)\n",
        "    return 100 * correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bYhcjsuCB-L0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25\n",
            "Epoch 01: Loss 0.5788 | Penalty 0.0156 | AvgAcc 79.81% | WorstAcc 9.38%\n",
            "Epoch 02: Loss 0.2259 | Penalty 0.0013 | AvgAcc 92.49% | WorstAcc 79.69%\n",
            "Epoch 03: Loss 0.0919 | Penalty 0.0019 | AvgAcc 97.33% | WorstAcc 89.06%\n",
            "Epoch 04: Loss 1.6118 | Penalty 0.0186 | AvgAcc 77.99% | WorstAcc 43.75%\n",
            "Epoch 05: Loss 1.7837 | Penalty 0.0087 | AvgAcc 54.44% | WorstAcc 17.19%\n",
            "Epoch 06: Loss 2.5697 | Penalty 0.0197 | AvgAcc 40.79% | WorstAcc 18.75%\n",
            "Epoch 07: Loss 1.6821 | Penalty 0.0020 | AvgAcc 36.63% | WorstAcc 17.19%\n",
            "Epoch 08: Loss 1.7365 | Penalty 0.0033 | AvgAcc 36.16% | WorstAcc 18.75%\n",
            "Epoch 09: Loss 1.7429 | Penalty 0.0025 | AvgAcc 34.61% | WorstAcc 12.50%\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 9\n",
        "print(min(len(loader) for loader in envs))\n",
        "for epoch in range(num_epochs):\n",
        "    irm.network.train()\n",
        "    env_iters = [iter(loader) for loader in envs]\n",
        "    num_batches = min(len(loader) for loader in envs)\n",
        "\n",
        "    epoch_loss = 0.0\n",
        "    epoch_penalty = 0.0\n",
        "    epoch_avg_acc = 0.0\n",
        "    epoch_worst_acc = 1.0  # start high, we’ll take min\n",
        "\n",
        "    for batch_idx in range(num_batches):\n",
        "        minibatches = []\n",
        "        for i, env_loader in enumerate(envs):\n",
        "            try:\n",
        "                x, y = next(env_iters[i])\n",
        "            except StopIteration:\n",
        "                env_iters[i] = iter(env_loader)\n",
        "                x, y = next(env_iters[i])\n",
        "            minibatches.append((x.to(device), y.to(device)))\n",
        "\n",
        "        metrics = irm.update(minibatches)\n",
        "\n",
        "        epoch_loss += metrics['loss']\n",
        "        epoch_penalty += metrics['penalty']\n",
        "        epoch_avg_acc += metrics['avg_acc']\n",
        "        epoch_worst_acc = min(epoch_worst_acc, metrics['worst_acc'])\n",
        "\n",
        "    # Normalize epoch averages\n",
        "    epoch_loss /= num_batches\n",
        "    epoch_penalty /= num_batches\n",
        "    epoch_avg_acc /= num_batches\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch+1:02d}: \"\n",
        "        f\"Loss {epoch_loss:.4f} | \"\n",
        "        f\"Penalty {epoch_penalty:.4f} | \"\n",
        "        f\"AvgAcc {epoch_avg_acc*100:.2f}% | \"\n",
        "        f\"WorstAcc {epoch_worst_acc*100:.2f}%\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bglvXrX7B-L0"
      },
      "source": [
        "### Evaluation on Source Domains"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KCo6I9fmB-L0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Art Accuracy: 42.72%\n",
            "Cartoon Accuracy: 35.59%\n",
            "Photo Accuracy: 57.14%\n",
            "\n",
            "All Source Domains Accuracy: 43.93%\n"
          ]
        }
      ],
      "source": [
        "art_accuracy = evaluate(irm, art_val_loader, device)\n",
        "print(f\"Art Accuracy: {art_accuracy:.2f}%\")\n",
        "\n",
        "cartoon_accuracy = evaluate(irm, cartoon_val_loader, device)\n",
        "print(f\"Cartoon Accuracy: {cartoon_accuracy:.2f}%\")\n",
        "\n",
        "photo_accuracy = evaluate(irm, photo_val_loader, device)\n",
        "print(f\"Photo Accuracy: {photo_accuracy:.2f}%\")\n",
        "\n",
        "source_accuracy = evaluate(irm, combined_val_loader, device)\n",
        "print(f\"\\nAll Source Domains Accuracy: {source_accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoHIIF6mB-L1"
      },
      "source": [
        "### Evaluation on Test Domain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1I0vH2HUB-L1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sketch Accuracy: 22.14%\n"
          ]
        }
      ],
      "source": [
        "sketch_accuracy = evaluate(irm, sketch_loader, device)\n",
        "print(f\"Sketch Accuracy: {sketch_accuracy:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
